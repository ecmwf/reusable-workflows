name: HPC Module Deployer
description: Build and deploy HPC modules with support for CMake, Python packages, and multi-stage builds

inputs:
  # Standard CD inputs
  name:
    description: 'Build name for identification'
    required: true
  ref_name:
    description: 'Git ref name for deployment'
    required: true
  dry_run:
    description: 'Dry run mode - build on HPC but skip module sync'
    required: false
    default: 'false'

  # HPC Authentication
  github_user:
    description: 'GitHub user for authentication'
    required: true
  github_token:
    description: 'GitHub PAT for repository access'
    required: true
  troika_user:
    description: 'HPC submission user'
    required: true

  # Compiler/Platform
  platform:
    description: 'Compiler platform (gnu-12.2.0, gnu-8.5.0, nvidia-22.11, intel-2021.4.0)'
    required: true

  # Installation
  install_type:
    description: 'Install type: module (to /usr/local/apps), perm (persistent), temp (temporary)'
    required: false
    default: 'module'
  install_prefix:
    description: 'Custom install prefix (overrides install_type default path)'
    required: false
    default: ''
  prefix_compiler_specific:
    description: 'Suffix <compiler>/<version> to install prefix'
    required: false
    default: 'false'

  # Build Configuration
  cmake_options:
    description: 'CMake/ecbuild options (comma-separated, e.g., -DENABLE_TESTS=ON,-DCMAKE_BUILD_TYPE=Release)'
    required: false
    default: ''
  ctest_options:
    description: 'CTest options for testing'
    required: false
    default: ''
  self_test:
    description: 'Run tests after building'
    required: false
    default: 'true'
  env_vars:
    description: 'Environment variables (JSON object, e.g., {"CTEST_PARALLEL_LEVEL": "4"})'
    required: false
    default: ''
  parallel:
    description: 'Number of parallel build jobs'
    required: false
    default: ''
  use_ninja:
    description: 'Use ninja build system instead of make'
    required: false
    default: 'true'
  force_build:
    description: 'Force rebuild, ignoring cache'
    required: false
    default: 'false'
  ecbundle:
    description: 'Use ecbundle for bundle-based projects'
    required: false
    default: 'false'
  bundle_yml:
    description: 'Path to bundle.yml for declarative bundle builds (auto-detected if present)'
    required: false
    default: ''
  bundle_vars:
    description: 'Variable substitutions for bundle.yml (JSON, e.g., {"BITBUCKET": "https://git.ecmwf.int"})'
    required: false
    default: ''

  # Dependencies
  dependencies:
    description: 'Build dependencies (owner/repo@ref format, one per line)'
    required: false
    default: ''
  dependency_cmake_options:
    description: 'CMake options for dependencies (YAML format: "owner/repo: -DOPTION=VALUE")'
    required: false
    default: ''
  python_dependencies:
    description: 'Python dependencies to build from source (owner/repo@ref format, one per line)'
    required: false
    default: ''
  python_version:
    description: 'Python version to use for build'
    required: false
    default: ''
  python_requirements:
    description: 'Path to pip requirements file for python packages'
    required: false
    default: ''
  python_toml_opt_dep_sections:
    description: 'List of optional dependency sections specified in pyproject.toml'
    required: false
    default: ''
  conda_deps:
    description: 'Conda packages to install'
    required: false
    default: ''

  # Stage Configuration (for multi-stage builds)
  stages:
    description: |
      JSON array of build stages for multi-Python or multi-config builds.
      Each stage object can have:
        - name: Stage identifier (required)
        - modules: Array of modules to load for this stage
        - cmake_options: CMake options for this stage (e.g., Boost/Python paths)
        - build_command: Custom build command (default: make -j$PARALLEL)
        - test_command: Optional test command to run before install (e.g., ctest --output-on-failure -j 8)
        - install_command: Custom install command (default: cmake --install .)
      Example: [{"name":"py312","modules":["python3/3.12","boost/1.87"],"cmake_options":"-DPython3_ROOT=...","test_command":"ctest --output-on-failure -j 8"}]
    required: false
    default: ''

  # Single-stage options (used when stages not provided)
  modules:
    description: 'Modules to load (JSON array or newline-separated, e.g., ["python/3.12", "boost/1.87"])'
    required: false
    default: ''
  install_command:
    description: 'Custom install command (overrides default cmake --install). Use $INSTALL_PREFIX for install path.'
    required: false
    default: ''

  # Finalization
  lock_permissions:
    description: 'Lock install directory permissions after build (chmod a-w)'
    required: false
    default: 'true'
  sync_module:
    description: 'Sync module to other clusters after build'
    required: false
    default: 'true'
  module_name:
    description: 'Module name for sync (if different from repo name)'
    required: false
    default: ''

  # Resource Options
  ntasks:
    description: 'Number of tasks for the job'
    required: false
    default: ''
  gpus:
    description: 'Number of GPUs required'
    required: false
    default: ''
  queue:
    description: 'HPC queue (nf, ng, deploy)'
    required: false
    default: ''

  # Advanced Options
  site:
    description: 'HPC site name'
    required: false
    default: 'hpc-batch'
  workdir:
    description: 'Work directory on HPC'
    required: false
    default: ''
  output_dir:
    description: 'Output directory on HPC'
    required: false
    default: ''
  post_script:
    description: 'Bash script to run after build (path relative to repo root)'
    required: false
    default: ''
  clean_before_install:
    description: 'Remove existing install directory before install (for nightly builds)'
    required: false
    default: 'false'
  install_lib_dir:
    description: 'CMake INSTALL_LIB_DIR value (lib or lib64). If set, adds -DINSTALL_LIB_DIR to cmake options.'
    required: false
    default: ''

runs:
  using: composite
  steps:
    - name: Parse configuration
      id: config
      shell: python3 {0}
      env:
        INPUT_STAGES: ${{ inputs.stages }}
      run: |
        import json
        import os
        import sys

        # Platform to compiler mapping
        platform_map = {
            'gnu-14.2.0': {
                'compiler': 'gnu-14.2.0',
                'compiler_cc': 'gcc',
                'compiler_cxx': 'g++',
                'compiler_fc': 'gfortran',
                'compiler_modules': 'gcc/14.2.0'
            },
            'gnu-12.2.0': {
                'compiler': 'gnu-12.2.0',
                'compiler_cc': 'gcc',
                'compiler_cxx': 'g++',
                'compiler_fc': 'gfortran',
                'compiler_modules': 'gcc/12.2.0'
            },
            'gnu-8.5.0': {
                'compiler': 'gnu-8.5.0',
                'compiler_cc': 'gcc',
                'compiler_cxx': 'g++',
                'compiler_fc': 'gfortran',
                'compiler_modules': 'gcc/8.5.0'
            },
            'nvidia-22.11': {
                'compiler': 'nvidia-22.11',
                'compiler_cc': 'nvc',
                'compiler_cxx': 'nvc++',
                'compiler_fc': 'nvfortran',
                'compiler_modules': 'prgenv/nvidia,nvidia/22.11'
            },
            'intel-2021.4.0': {
                'compiler': 'intel-2021.4.0',
                'compiler_cc': 'icc',
                'compiler_cxx': 'icpc',
                'compiler_fc': 'ifort',
                'compiler_modules': 'prgenv/intel,intel/2021.4.0'
            }
        }

        platform = "${{ inputs.platform }}"
        if platform not in platform_map:
            print(f"::error::Unknown platform '{platform}'")
            print(f"Available platforms: {', '.join(platform_map.keys())}")
            sys.exit(1)

        compiler_info = platform_map[platform]

        # Check if staged build
        stages_input = os.environ.get('INPUT_STAGES', '').strip()
        use_staged = bool(stages_input)

        dry_run = '${{ inputs.dry_run }}' == 'true'
        sync_module_input = '${{ inputs.sync_module }}' == 'true'
        do_sync = not dry_run and sync_module_input

        install_prefix_input = '''${{ inputs.install_prefix }}'''.strip()
        install_type = '${{ inputs.install_type }}'
        module_name = '''${{ inputs.module_name }}'''.strip() or '${{ github.repository }}'.split('/')[-1]
        ref_name = '${{ inputs.ref_name }}'
        prefix_compiler_specific = '${{ inputs.prefix_compiler_specific }}' == 'true'

        if install_prefix_input:
            install_prefix = install_prefix_input
        elif install_type == 'module':
            install_prefix = f'/usr/local/apps/{module_name}/{ref_name}'
        else:
            install_prefix = '$' + '{TMPDIR}' + f'/install/{module_name}/{ref_name}'

        if prefix_compiler_specific:
            base_install_prefix = install_prefix
            install_prefix = f"{install_prefix}/{compiler_info['compiler']}"
        else:
            base_install_prefix = install_prefix

        # Write outputs
        with open(os.environ['GITHUB_OUTPUT'], 'a', encoding='utf-8') as f:
            f.write(f"use_staged={'true' if use_staged else 'false'}\n")
            f.write(f"do_sync={'true' if do_sync else 'false'}\n")
            f.write(f"install_prefix={install_prefix}\n")
            f.write(f"base_install_prefix={base_install_prefix}\n")
            for key, value in compiler_info.items():
                f.write(f"{key}={value}\n")

        print(f"Platform: {platform}")
        print(f"Compiler: {compiler_info['compiler']}")
        print(f"Build mode: {'staged' if use_staged else 'standard'}")
        print(f"Install prefix: {install_prefix}")
        print(f"Do sync: {do_sync}")

    - name: Generate build template
      id: template
      shell: python3 {0}
      env:
        INPUT_STAGES: ${{ inputs.stages }}
        INPUT_CMAKE_OPTIONS: ${{ inputs.cmake_options }}
        INPUT_CTEST_OPTIONS: ${{ inputs.ctest_options }}
        INPUT_DEPENDENCIES: ${{ inputs.dependencies }}
        INPUT_DEPENDENCY_CMAKE_OPTIONS: ${{ inputs.dependency_cmake_options }}
        INPUT_PYTHON_DEPENDENCIES: ${{ inputs.python_dependencies }}
        INPUT_MODULES: ${{ inputs.modules }}
        INPUT_ENV_VARS: ${{ inputs.env_vars }}
        INPUT_INSTALL_LIB_DIR: ${{ inputs.install_lib_dir }}
        INPUT_BUNDLE_YML: ${{ inputs.bundle_yml }}
        INPUT_BUNDLE_VARS: ${{ inputs.bundle_vars }}
      run: |
        import hashlib
        import json
        import os
        import yaml
        from pathlib import Path
        from jinja2 import Environment, FileSystemLoader

        # Load Jinja templates
        action_dir = Path('${{ github.action_path }}')
        template_dir = action_dir / 'templates'
        env = Environment(
            loader=FileSystemLoader(template_dir),
            trim_blocks=True,
            lstrip_blocks=True,
        )

        # Check if staged build
        stages_input = os.environ.get('INPUT_STAGES', '').strip()
        use_staged = bool(stages_input)

        # Parse inputs from environment variables
        cmake_options_input = os.environ.get('INPUT_CMAKE_OPTIONS', '').strip()
        ctest_options_input = os.environ.get('INPUT_CTEST_OPTIONS', '').strip()
        dependencies_input = os.environ.get('INPUT_DEPENDENCIES', '').strip()
        dep_cmake_options_input = os.environ.get('INPUT_DEPENDENCY_CMAKE_OPTIONS', '').strip()
        python_deps_input = os.environ.get('INPUT_PYTHON_DEPENDENCIES', '').strip()
        modules_input = os.environ.get('INPUT_MODULES', '').strip()
        env_vars_input = os.environ.get('INPUT_ENV_VARS', '').strip()
        install_lib_dir = os.environ.get('INPUT_INSTALL_LIB_DIR', '').strip()

        repository = '${{ github.repository }}'
        repo_owner, repo_name = repository.split('/')
        ref_name = '${{ inputs.ref_name }}'
        compiler = '${{ steps.config.outputs.compiler }}'
        compiler_modules = '${{ steps.config.outputs.compiler_modules }}'
        install_prefix = '${{ steps.config.outputs.install_prefix }}'
        base_install_prefix = '${{ steps.config.outputs.base_install_prefix }}'
        module_name = '''${{ inputs.module_name }}'''.strip() or repo_name
        parallel = '''${{ inputs.parallel }}'''.strip() or '64'
        ntasks = '''${{ inputs.ntasks }}'''.strip() or '1'
        gpus = '''${{ inputs.gpus }}'''.strip()
        queue = '''${{ inputs.queue }}'''.strip() or 'nf'
        site = '${{ inputs.site }}'
        do_sync = '${{ steps.config.outputs.do_sync }}' == 'true'
        lock_permissions = '${{ inputs.lock_permissions }}' == 'true'
        use_ninja = '${{ inputs.use_ninja }}' == 'true'
        self_test = '${{ inputs.self_test }}' == 'true'
        force_build = '${{ inputs.force_build }}' == 'true'
        ecbundle = '${{ inputs.ecbundle }}' == 'true'
        clean_before_install = '${{ inputs.clean_before_install }}' == 'true'
        python_version = '''${{ inputs.python_version }}'''.strip()
        requirements_path = '''${{ inputs.python_requirements }}'''.strip() or 'requirements.txt'
        toml_opt_dep_sections = '''${{ inputs.python_toml_opt_dep_sections }}'''.strip()
        conda_deps = '''${{ inputs.conda_deps }}'''.strip()
        post_script = '''${{ inputs.post_script }}'''.strip() or None
        bundle_yml_input = os.environ.get('INPUT_BUNDLE_YML', '').strip()
        bundle_vars_input = os.environ.get('INPUT_BUNDLE_VARS', '').strip()

        if use_ninja:
            generator = '-GNinja'
            build_cmd = 'ninja'
        else:
            generator = ''
            build_cmd = 'make'

        # Build generic modules list (compiler + ninja if enabled)
        generic_modules = compiler_modules.split(',')
        if use_ninja:
            generic_modules.append('ninja')

        # === BUILD COMMON CONTEXT ===
        # Parse cmake options (comma-separated to list)
        cmake_options = [opt.strip() for opt in cmake_options_input.split(',') if opt.strip()] if cmake_options_input else []
        ctest_options = [opt.strip() for opt in ctest_options_input.split(',') if opt.strip()] if ctest_options_input else []

        # Add install lib dir if specified
        if install_lib_dir:
            cmake_options.insert(0, f'-DINSTALL_LIB_DIR={install_lib_dir}')

        # Parse dependency cmake options (YAML format)
        dep_cmake_map = {}
        if dep_cmake_options_input:
            try:
                dep_cmake_map = yaml.safe_load(dep_cmake_options_input) or {}
            except yaml.YAMLError:
                print(f"::warning::Could not parse dependency_cmake_options as YAML")

        # Parse modules
        package_modules = []
        if modules_input:
            try:
                package_modules = json.loads(modules_input)
            except json.JSONDecodeError:
                # Try as newline/comma-separated
                package_modules = [m.strip() for m in modules_input.replace('\n', ',').split(',') if m.strip()]

        # Parse environment variables
        env_list = []
        if env_vars_input:
            try:
                env_dict = json.loads(env_vars_input)
                env_list = [f'{k}={v}' for k, v in env_dict.items()]
            except json.JSONDecodeError:
                print(f"::warning::Could not parse env_vars as JSON")

        # Helper to generate cache key
        def cache_key(name, ref, cmake_opts):
            key_data = f"{name}:{ref}:{compiler}:{':'.join(cmake_opts or [])}"
            return f"{name}-{hashlib.sha256(key_data.encode()).hexdigest()[:12]}"

        # Parse bundle.yml (ecmwf-toolbox)
        def parse_bundle_yml(bundle_path, bundle_vars, github_user, github_token, install_prefix):
            """Parse bundle.yml and return packages in dependency order."""
            import re
            from collections import deque

            with open(bundle_path, 'r') as f:
                bundle_data = yaml.safe_load(f)

            # Default variable substitutions
            var_map = {
                'BITBUCKET': 'https://github.com',
                'GITHUB': 'https://github.com',
            }
            # Override with user-provided vars
            if bundle_vars:
                try:
                    user_vars = json.loads(bundle_vars)
                    var_map.update(user_vars)
                except json.JSONDecodeError:
                    print(f"::warning::Could not parse bundle_vars as JSON")

            def substitute_vars(text):
                """Replace ${VAR} patterns with values from var_map."""
                if not text:
                    return text
                for var, val in var_map.items():
                    text = text.replace('${' + var + '}', val)
                return text

            def inject_auth(url, user, token):
                """Inject auth credentials into git URL."""
                if url.startswith('https://'):
                    # https://github.com/... -> https://user:token@github.com/...
                    return url.replace('https://', f'https://{user}:{token}@', 1)
                return url

            # Extract projects from bundle
            projects = {}
            for key, value in bundle_data.items():
                if key in ('version', 'name', 'cmake', 'options'):
                    continue
                if isinstance(value, dict) and 'git' in value:
                    projects[key] = value

            # Build dependency graph and project info
            graph = {name: [] for name in projects}
            in_degree = {name: 0 for name in projects}

            for name, proj in projects.items():
                requires = proj.get('require', '')
                if requires:
                    # require can be space-separated list
                    deps = requires.split()
                    for dep in deps:
                        if dep in graph:
                            graph[dep].append(name)
                            in_degree[name] += 1

            # Topological sort (Kahn's algorithm)
            sorted_projects = []
            queue = deque([name for name, deg in in_degree.items() if deg == 0])

            while queue:
                current = queue.popleft()
                sorted_projects.append(current)
                for neighbor in graph[current]:
                    in_degree[neighbor] -= 1
                    if in_degree[neighbor] == 0:
                        queue.append(neighbor)

            if len(sorted_projects) != len(projects):
                print(f"::error::Circular dependency detected in bundle.yml")
                import sys
                sys.exit(1)

            # Build packages list
            packages = []
            for i, name in enumerate(sorted_projects):
                proj = projects[name]
                git_url = substitute_vars(proj.get('git', ''))
                git_url_with_auth = inject_auth(git_url, github_user, github_token)

                # Parse owner/repo from git URL
                # https://github.com/ecmwf/ecbuild.git -> ecmwf, ecbuild
                match = re.search(r'github\.com[/:]([^/]+)/([^/.]+)', git_url)
                if match:
                    owner, repo = match.groups()
                else:
                    owner, repo = 'ecmwf', name

                ref = proj.get('version', proj.get('branch', proj.get('tag', 'main')))

                # Parse cmake options
                proj_cmake = proj.get('cmake', '')
                if isinstance(proj_cmake, str):
                    cmake_opts = [opt.strip() for opt in proj_cmake.split() if opt.strip()]
                else:
                    cmake_opts = []

                # First project (ecbuild) goes to temp deps, others to install_prefix
                if i == 0:
                    prefix = '$' + '{TMPDIR}' + f'/deps/{name}'
                else:
                    prefix = install_prefix

                packages.append({
                    'name': name,
                    'owner': owner,
                    'repo': repo,
                    'ref': ref,
                    'type': 'bundle-project',
                    'prefix': prefix,
                    'cmake_options': cmake_opts,
                    'ctest_options': [],
                    'modules': [],
                    'cache_key': cache_key(name, ref, cmake_opts),
                    'subdir': '',
                    'git_url': git_url_with_auth,
                })

            return packages

        # Auto-detect bundle.yml
        use_bundle_yml = False
        bundle_packages = []

        if bundle_yml_input:
            bundle_yml_path = bundle_yml_input
            if os.path.exists(bundle_yml_path):
                use_bundle_yml = True
        else:
            # Auto-detect in current directory
            if os.path.exists('bundle.yml'):
                bundle_yml_path = 'bundle.yml'
                use_bundle_yml = True

        if use_bundle_yml:
            print(f"Detected bundle.yml at: {bundle_yml_path}")
            bundle_packages = parse_bundle_yml(
                bundle_yml_path,
                bundle_vars_input,
                '{{ github_user }}',  # Template placeholder
                '{{ github_token }}',  # Template placeholder
                install_prefix
            )
            print(f"Bundle projects (in dependency order): {[p['name'] for p in bundle_packages]}")

        # Build packages list
        packages = []

        # Use bundle packages if bundle.yml detected, otherwise parse dependencies normally
        if use_bundle_yml:
            packages = bundle_packages
        else:
            # Parse dependencies
            for dep in dependencies_input.splitlines():
                dep = dep.strip()
                if not dep:
                    continue
                if '@' in dep:
                    dep_repo, dep_ref = dep.rsplit('@', 1)
                else:
                    dep_repo, dep_ref = dep, 'main'

                if '/' in dep_repo:
                    dep_owner, dep_name = dep_repo.split('/', 1)
                else:
                    dep_owner, dep_name = 'ecmwf', dep_repo

                # Get dependency-specific cmake options
                dep_cmake = dep_cmake_map.get(dep_repo, '')
                dep_cmake_list = [opt.strip() for opt in dep_cmake.split(',') if opt.strip()] if dep_cmake else []

                # Dependency prefix is in workdir deps area
                dep_prefix = '$' + '{TMPDIR}' + f'/deps/{dep_name}'

                packages.append({
                    'name': dep_name,
                    'owner': dep_owner,
                    'repo': dep_name,
                    'ref': dep_ref,
                    'type': 'dependency',
                    'prefix': dep_prefix,
                    'cmake_options': dep_cmake_list,
                    'ctest_options': [],
                    'modules': [],
                    'cache_key': cache_key(dep_name, dep_ref, dep_cmake_list),
                    'subdir': '',
                })

            # Add main package (CMake) - always add for staged builds, or when no python_version
            if use_staged or not python_version:
                packages.append({
                    'name': repo_name,
                    'owner': repo_owner,
                    'repo': repo_name,
                    'ref': ref_name,
                    'type': 'main',
                    'prefix': install_prefix,
                    'cmake_options': cmake_options,
                    'ctest_options': ctest_options,
                    'modules': package_modules,
                    'cache_key': cache_key(repo_name, ref_name, cmake_options),
                    'subdir': '',
                })

            # Parse Python dependencies
            for dep in python_deps_input.splitlines():
                dep = dep.strip()
                if not dep:
                    continue
                if '@' in dep:
                    dep_repo, dep_ref = dep.rsplit('@', 1)
                else:
                    dep_repo, dep_ref = dep, 'main'

                if '/' in dep_repo:
                    dep_owner, dep_name = dep_repo.split('/', 1)
                else:
                    dep_owner, dep_name = 'ecmwf', dep_repo

                packages.append({
                    'name': dep_name,
                    'owner': dep_owner,
                    'repo': dep_name,
                    'ref': dep_ref,
                    'type': 'dependency-python',
                    'prefix': '',
                    'cmake_options': [],
                    'ctest_options': [],
                    'modules': [],
                    'cache_key': '',
                    'subdir': '',
                })

            # Add main Python package
            if python_version:
                packages.append({
                    'name': repo_name,
                    'owner': repo_owner,
                    'repo': repo_name,
                    'ref': ref_name,
                    'type': 'main-python',
                    'prefix': install_prefix,
                    'cmake_options': [],
                    'ctest_options': [],
                    'modules': package_modules,
                    'cache_key': '',
                    'subdir': '',
                })

        # Build ci_options dict
        ci_options = {
            'parallel': int(parallel),
            'cpus_per_task': int(parallel),
            'ntasks': int(ntasks),
            'gpus': int(gpus) if gpus else 0,
            'self_test': self_test,
            'force_build': force_build,
            'workdir': '$' + '{TMPDIR}',
            'output_path': '',  # Set by generic.jinja wrapper
            'python_version': python_version or '3.12',
            'requirements_path': requirements_path,
            'toml_opt_dep_sections': toml_opt_dep_sections,
            'conda_deps': conda_deps,
            'post_script': post_script,
            'main_package_name': repo_name,
            'compiler': compiler,
            'mkdir': [],
            'ecbundle': ecbundle,
            'use_bundle_yml': use_bundle_yml,
            'pytest_cmd': None,
            'install_type': '${{ inputs.install_type }}',
            'prefix_compiler_specific': '${{ inputs.prefix_compiler_specific }}' == 'true',
            'clean_before_install': clean_before_install,
            'install_prefix': install_prefix,
            'base_install_prefix': base_install_prefix,
            'sync_clusters': ['aa', 'ab'],
            'sync_module': do_sync,
            'module_name': module_name,
            'queue': queue,
            'hpc': 'lumi' if site == 'lumi' else 'atos',
            'hpc_config': {'enable_cache': True},
            'lock_permissions': lock_permissions,
        }

        # Build github dict (with template placeholders for secrets)
        github = {
            'user': '{{ github_user }}',
            'token': '{{ github_token }}',
        }

        # === RENDER TEMPLATE ===
        template = env.get_template('build-job.jinja')

        # Parse stages if provided
        stages = []
        if use_staged:
            try:
                stages = json.loads(stages_input)
            except json.JSONDecodeError as e:
                print(f"::error::Failed to parse stages JSON: {e}")
                print(f"Input was: {stages_input[:200]}...")
                import sys
                sys.exit(1)

            # Normalize stages to ensure required fields
            for i, stage in enumerate(stages):
                stage.setdefault('name', f'stage-{i}')
                stage.setdefault('modules', [])
                stage.setdefault('cmake_options', '')
                stage.setdefault('build_command', '')
                stage.setdefault('test_command', '')
                stage.setdefault('install_command', '')

        # Render template (stages list is empty for standard builds)
        rendered = template.render(
            packages=packages,
            ci_options=ci_options,
            generic_modules=generic_modules,
            env=env_list,
            github=github,
            stages=stages,
        )

        # Generate sbatch options using the macro from macros.jinja
        sbatch_template = env.from_string(
            "{% from 'macros.jinja' import sbatch_options with context %}{{ sbatch_options() }}"
        )
        sbatch = sbatch_template.render(
            site=site,
            queue=queue,
            ntasks=ntasks,
            parallel=parallel,
            gpus=gpus,
        ).strip()

        # Write outputs
        with open(os.environ['GITHUB_OUTPUT'], 'a', encoding='utf-8') as f:
            f.write("template<<EOF\n")
            f.write(rendered)
            f.write("\nEOF\n")
            f.write("sbatch_options<<SBATCH_EOF\n")
            f.write(sbatch)
            f.write("\nSBATCH_EOF\n")

        print("Generated template:")
        print(rendered[:2000])
        if len(rendered) > 2000:
            print(f"\n... ({len(rendered) - 2000} more characters)")
        print("\nSBATCH options:")
        print(sbatch)

    - name: Build with ci-hpc-generic
      uses: ecmwf/reusable-workflows/ci-hpc-generic@v2
      with:
        troika_user: ${{ inputs.troika_user }}
        site: ${{ inputs.site }}
        workdir: ${{ inputs.workdir }}
        output_dir: ${{ inputs.output_dir }}
        template: ${{ steps.template.outputs.template }}
        sbatch_options: ${{ steps.template.outputs.sbatch_options }}
        template_data: |
          github_user: ${{ inputs.github_user }}
          github_token: ${{ inputs.github_token }}
          install_prefix: ${{ steps.config.outputs.install_prefix }}
